{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import scipy.sparse as spa\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# generate problem data\n",
    "n = 4   # nodes\n",
    "k = 2   # suppliers (with prices p)\n",
    "c = 2   # retail (with demand d)\n",
    "m = 8   # links\n",
    "\n",
    "supply_links = [0, 1]\n",
    "retail_links = [6, 7]\n",
    "internode_links = [2, 3, 4, 5]\n",
    "\n",
    "# Incidence matrices (nodes x links)\n",
    "A_in = np.array([[1, 0, 0, 0, 0, 0, 0, 0],   # 1 (supply)\n",
    "                 [0, 1, 0, 0, 0, 0, 0, 0],   # 2 (supply)\n",
    "                 [0, 0, 1, 0, 0, 1, 0, 0],   # 3 (retail)\n",
    "                 [0, 0, 0, 1, 1, 0, 0, 0],   # 4 (retail)\n",
    "                 ])\n",
    "\n",
    "A_out = np.array([[0, 0, 1, 1, 0, 0, 0, 0],   # 1 (supply)\n",
    "                  [0, 0, 0, 0, 1, 0, 0, 0],   # 2 (supply)\n",
    "                  [0, 0, 0, 0, 0, 0, 1, 0],   # 3 (retail)\n",
    "                  [0, 0, 0, 0, 0, 1, 0, 1],   # 4 (retail)\n",
    "                  ])\n",
    "\n",
    "# Prices\n",
    "mu_p = torch.tensor([0, 0.1]).double()\n",
    "sigma_p = torch.tensor([0.2, 0.2]).double()\n",
    "mean_p = torch.exp(mu_p + sigma_p ** 2 /2).double().view(k, 1)\n",
    "var_p = (torch.exp(sigma_p ** 2) - 1) * torch.exp(2 * mean_p + sigma_p ** 2)\n",
    "\n",
    "# Demands\n",
    "mu_d = torch.tensor([0.0, 0.4]).double()\n",
    "sigma_d = torch.tensor([0.2, 0.2]).double()\n",
    "mean_d = torch.exp(mu_d + sigma_d ** 2 /2).double().view(c, 1)\n",
    "var_d = (torch.exp(sigma_d ** 2) - 1) * torch.exp(2 * mean_d + sigma_d ** 2)\n",
    "\n",
    "# Uncertainty distribution (prices and demands)\n",
    "w_dist = torch.distributions.log_normal.LogNormal(torch.cat([mu_p, mu_d], 0), \n",
    "                                                  torch.cat([sigma_p, sigma_d], 0))\n",
    "\n",
    "# Capacities\n",
    "h_max = 3. # Maximum capacity in every node\n",
    "u_max = 2. # Link flow capacity\n",
    "\n",
    "# Storage cost parameters, W(x) = alpha'x + beta'x^2 + gamma\n",
    "alpha = 0.01\n",
    "beta = 0.01\n",
    "\n",
    "# Transportation cost parameters\n",
    "tau = 0.05 * np.ones((m - k - c, 1))\n",
    "tau_th = torch.tensor(tau, dtype=torch.double)\n",
    "r = 1.3 * np.ones((k, 1))\n",
    "r_th = torch.tensor(r, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0703, 0.9826, 1.3146, 1.1100], dtype=torch.float64)\n",
      "tensor([[1.0202],\n",
      "        [1.1275]], dtype=torch.float64)\n",
      "tensor([[0.3268, 0.3268],\n",
      "        [0.4050, 0.4050]], dtype=torch.float64)\n",
      "tensor([[1.0202],\n",
      "        [1.5220]], dtype=torch.float64)\n",
      "tensor([[0.3268, 0.3268],\n",
      "        [0.8915, 0.8915]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(w_dist.sample())\n",
    "print(mean_p)\n",
    "print(var_p)\n",
    "print(mean_d)\n",
    "print(var_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define linear dynamics\n",
    "# x = (h, p^{wh}, d) \n",
    "# u = u\n",
    "# w = (p^{wh}, d)\n",
    "# x_{t+1} = Ax_{t} + Bu_{t} + w\n",
    "A_d = np.bmat([[np.eye(n), np.zeros((n, k+c))],\n",
    "              [np.zeros((k+c, n)), np.zeros((k+c, k+c))]])\n",
    "A_d_th = torch.tensor(A_d, dtype=torch.double)\n",
    "B_d = np.vstack([A_in - A_out,\n",
    "                 np.zeros((k+c, m))])\n",
    "B_d_th = torch.tensor(B_d, dtype=torch.double)\n",
    "n_x, n_u = B_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup policy\n",
    "# Parameters\n",
    "P_sqrt = cp.Parameter((n, n)) # 4x4\n",
    "q = cp.Parameter((n, 1)) # 4x1\n",
    "x = cp.Parameter((n_x, 1)) # 8x1\n",
    "h, p, d = x[:n], x[n:n+k], x[n+k:]\n",
    "\n",
    "# Variables\n",
    "u = cp.Variable((n_u, 1))\n",
    "h_next = cp.Variable((n, 1))\n",
    "\n",
    "# Cvxpy Layer\n",
    "stage_cost = cp.vstack([p, tau, -r]).T @ u\n",
    "next_stage_cost = cp.sum_squares(P_sqrt @ h_next) + q.T @ h_next\n",
    "constraints = [h_next == h + (A_in - A_out) @ u, \n",
    "               h_next <= h_max,  \n",
    "               0 <= u, u <= u_max,\n",
    "               A_out @ u <= h, u[retail_links] <= d,\n",
    "              ]\n",
    "prob = cp.Problem(cp.Minimize(stage_cost + next_stage_cost), constraints)\n",
    "policy = CvxpyLayer(prob, [x, P_sqrt, q], [u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_cost(x, u):\n",
    "    assert x.shape[0] == u.shape[0]\n",
    "    batch_size = x.shape[0]\n",
    "    r_batch = r_th.repeat(batch_size, 1, 1)\n",
    "    tau_batch = tau_th.repeat(batch_size, 1, 1)\n",
    "    \n",
    "    h, p, dh = x[:,:n], x[:, n:n+k], x[:, n+k:]\n",
    "    \n",
    "    m = len(u)    \n",
    "    \n",
    "    # Selling + buying + shipping cost\n",
    "    s_vec = torch.cat([p, tau_batch, -r_batch], 1).double()\n",
    "    S = torch.bmm(s_vec.transpose(1, 2), u)\n",
    "    H = alpha * h + beta * (h ** 2)  # Storage cost\n",
    "        \n",
    "    return torch.sum(S, 1) + torch.sum(H, 1)\n",
    "\n",
    "def simulate(x, u):\n",
    "    assert x.shape[0] == u.shape[0]\n",
    "    batch_size = x.shape[0]\n",
    "\n",
    "    A_batch = A_d_th.repeat(batch_size, 1, 1)\n",
    "    B_batch = B_d_th.repeat(batch_size, 1, 1)\n",
    "    \n",
    "    zer = torch.zeros(batch_size, n, 1).double()\n",
    "    w = w_dist.sample((batch_size,)).double().view((batch_size, k + c, 1))\n",
    "    w_batch = torch.cat([zer, w], 1).double()\n",
    "    \n",
    "    return torch.bmm(A_batch, x) + torch.bmm(B_batch, u) + w_batch\n",
    "\n",
    "    \n",
    "def loss(policy, params, time_horizon, batch_size=1, seed=None):\n",
    "    P_sqrt, q = params\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "    # Batchify input\n",
    "    x_b_0 = h_max * torch.rand(batch_size, n, 1).double()\n",
    "    w_0 = w_dist.sample((batch_size,)).double().view((batch_size, k+c, 1))\n",
    "    x_batch = torch.cat([x_b_0, w_0], 1).double()\n",
    "\n",
    "    # Repeat parameter values\n",
    "    P_sqrt_batch = P_sqrt.repeat(batch_size, 1, 1)\n",
    "    q_batch = q.repeat(batch_size, 1, 1)\n",
    "\n",
    "    cost = 0.0\n",
    "    x_t = x_batch\n",
    "    x_hist = [x_batch]\n",
    "    u_hist = []\n",
    "    for t in range(time_horizon):\n",
    "        u_t = policy(x_t, P_sqrt_batch, q_batch, solver_args={\"acceleration_lookback\": 0})[0]\n",
    "        x_t = simulate(x_t, u_t) \n",
    "        cost += stage_cost(x_t, u_t).mean() / time_horizon\n",
    "        x_hist.append(x_t)\n",
    "        u_hist.append(u_t)\n",
    "        \n",
    "    return cost, x_hist, u_hist\n",
    "\n",
    "def monte_carlo(policy, params, time_horizon, batch_size=1, trials=10, seed=None):\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    results = []\n",
    "    x = []\n",
    "    u = []\n",
    "    \n",
    "    for i in range(trials):\n",
    "        cost, x_hist, u_hist = loss(policy, params, time_horizon, batch_size=batch_size, seed=seed)\n",
    "        results.append(cost.item())\n",
    "        x.append(x_hist)\n",
    "        u.append(u_hist)\n",
    "    return results, x, u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(policy, params, time_horizon, lr, epochs, batch_size):\n",
    "    opt = torch.optim.SGD(params, lr=lr)\n",
    "    val_costs = []\n",
    "    best_params = []\n",
    "    # updating without gradient\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        with torch.no_grad():\n",
    "            val_cost_mc, x_behav, u_behav = monte_carlo(policy, params, time_horizon, 1, trials=10, seed=0)\n",
    "            val_cost = np.mean(val_cost_mc)\n",
    "            val_costs.append(val_cost)\n",
    "\n",
    "        torch.manual_seed(epoch)\n",
    "        opt.zero_grad()\n",
    "        cost, _, _,  = loss(policy, params, time_horizon, batch_size, seed=epoch+1)\n",
    "        cost.backward()\n",
    "        print(\"epoch %d, valid %.4e\" % (epoch, val_cost))         \n",
    "        # TODO: Print gradient norm (possibly clip it)\n",
    "        # torch.nn.utils.clip_grad_norm_(params, 1)\n",
    "#         for p in params:\n",
    "#             print(p.grad.data.norm(2).item())\n",
    "        opt.step()\n",
    "#         scheduler.step(val_cost)        \n",
    "    return val_costs, [np.array(p.detach().numpy()) for p in params], x_behav, u_behav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_aggregate(policy, param_set, time_horizon, batch_size=1, seed=None):\n",
    "    costs = []\n",
    "    for param in param_set:\n",
    "        costs.append(loss(policy, params, time_horizon, batch_size=1, seed=None)[0])\n",
    "\n",
    "    best_zetas = np.argsort(costs) # update to return parameters\n",
    "    return best_zetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline cost:  -0.4186972256870515\n",
      "Perform training\n",
      "epoch 0, valid -4.1870e-01\n",
      "epoch 1, valid -4.3153e-01\n",
      "epoch 2, valid -4.3953e-01\n",
      "epoch 3, valid -4.4775e-01\n",
      "epoch 4, valid -4.5500e-01\n",
      "epoch 5, valid -4.5873e-01\n",
      "epoch 6, valid -4.6325e-01\n",
      "epoch 7, valid -4.6693e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qasimwani/opt/anaconda3/lib/python3.7/site-packages/diffcp/cone_program.py:282: UserWarning: Solved/Inaccurate.\n",
      "  warnings.warn(\"Solved/Inaccurate.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, valid -4.7074e-01\n",
      "epoch 9, valid -4.7343e-01\n",
      "epoch 10, valid -4.7677e-01\n",
      "epoch 11, valid -4.7715e-01\n",
      "epoch 12, valid -4.7955e-01\n",
      "epoch 13, valid -4.7835e-01\n",
      "epoch 14, valid -4.7947e-01\n",
      "epoch 15, valid -4.8181e-01\n",
      "epoch 16, valid -4.8195e-01\n",
      "epoch 17, valid -4.8432e-01\n",
      "epoch 18, valid -4.8424e-01\n",
      "epoch 19, valid -4.8378e-01\n",
      "epoch 20, valid -4.8588e-01\n",
      "epoch 21, valid -4.8703e-01\n",
      "epoch 22, valid -4.8765e-01\n",
      "epoch 23, valid -4.8866e-01\n",
      "epoch 24, valid -4.8799e-01\n",
      "epoch 25, valid -4.8897e-01\n",
      "epoch 26, valid -4.9042e-01\n",
      "epoch 27, valid -4.9007e-01\n",
      "epoch 28, valid -4.8994e-01\n",
      "epoch 29, valid -4.9170e-01\n",
      "epoch 30, valid -4.9186e-01\n",
      "epoch 31, valid -4.9244e-01\n",
      "epoch 32, valid -4.9314e-01\n",
      "epoch 33, valid -4.9292e-01\n",
      "epoch 34, valid -4.9280e-01\n",
      "epoch 35, valid -4.9304e-01\n",
      "epoch 36, valid -4.9366e-01\n",
      "epoch 37, valid -4.9436e-01\n",
      "epoch 38, valid -4.9459e-01\n",
      "epoch 39, valid -4.9517e-01\n",
      "epoch 40, valid -4.9552e-01\n",
      "epoch 41, valid -4.9585e-01\n",
      "epoch 42, valid -4.9660e-01\n",
      "epoch 43, valid -4.9719e-01\n",
      "epoch 44, valid -4.9778e-01\n",
      "epoch 45, valid -4.9796e-01\n",
      "epoch 46, valid -4.9831e-01\n",
      "epoch 47, valid -4.9905e-01\n",
      "epoch 48, valid -4.9952e-01\n",
      "epoch 49, valid -4.9975e-01\n",
      "epoch 50, valid -5.0033e-01\n",
      "epoch 51, valid -5.0081e-01\n",
      "epoch 52, valid -5.0155e-01\n",
      "epoch 53, valid -5.0217e-01\n",
      "epoch 54, valid -5.0267e-01\n",
      "epoch 55, valid -5.0275e-01\n",
      "epoch 56, valid -5.0304e-01\n",
      "epoch 57, valid -5.0368e-01\n",
      "epoch 58, valid -5.0424e-01\n",
      "epoch 59, valid -5.0434e-01\n",
      "epoch 60, valid -5.0475e-01\n",
      "epoch 61, valid -5.0516e-01\n",
      "epoch 62, valid -5.0541e-01\n",
      "epoch 63, valid -5.0588e-01\n",
      "epoch 64, valid -5.0655e-01\n",
      "epoch 65, valid -5.0691e-01\n",
      "epoch 66, valid -5.0706e-01\n",
      "epoch 67, valid -5.0716e-01\n",
      "epoch 68, valid -5.0741e-01\n",
      "epoch 69, valid -5.0761e-01\n",
      "epoch 70, valid -5.0803e-01\n",
      "epoch 71, valid -5.0830e-01\n",
      "epoch 72, valid -5.0894e-01\n",
      "epoch 73, valid -5.0915e-01\n",
      "epoch 74, valid -5.0921e-01\n",
      "epoch 75, valid -5.0941e-01\n",
      "epoch 76, valid -5.0953e-01\n",
      "epoch 77, valid -5.0999e-01\n",
      "epoch 78, valid -5.1087e-01\n",
      "epoch 79, valid -5.1091e-01\n",
      "epoch 80, valid -5.1098e-01\n",
      "epoch 81, valid -5.1125e-01\n",
      "epoch 82, valid -5.1144e-01\n",
      "epoch 83, valid -5.1186e-01\n",
      "epoch 84, valid -5.1209e-01\n",
      "epoch 85, valid -5.1236e-01\n",
      "epoch 86, valid -5.1256e-01\n",
      "epoch 87, valid -5.1267e-01\n",
      "epoch 88, valid -5.1278e-01\n",
      "epoch 89, valid -5.1339e-01\n",
      "epoch 90, valid -5.1389e-01\n",
      "epoch 91, valid -5.1401e-01\n",
      "epoch 92, valid -5.1412e-01\n",
      "epoch 93, valid -5.1416e-01\n",
      "epoch 94, valid -5.1432e-01\n",
      "epoch 95, valid -5.1443e-01\n",
      "epoch 96, valid -5.1448e-01\n",
      "epoch 97, valid -5.1455e-01\n",
      "epoch 98, valid -5.1461e-01\n",
      "epoch 99, valid -5.1457e-01\n",
      "epoch 100, valid -5.1491e-01\n",
      "epoch 101, valid -5.1502e-01\n",
      "epoch 102, valid -5.1482e-01\n",
      "epoch 103, valid -5.1485e-01\n",
      "epoch 104, valid -5.1495e-01\n",
      "epoch 105, valid -5.1529e-01\n",
      "epoch 106, valid -5.1524e-01\n",
      "epoch 107, valid -5.1535e-01\n",
      "epoch 108, valid -5.1534e-01\n",
      "epoch 109, valid -5.1560e-01\n",
      "epoch 110, valid -5.1589e-01\n",
      "epoch 111, valid -5.1617e-01\n",
      "epoch 112, valid -5.1609e-01\n",
      "epoch 113, valid -5.1630e-01\n",
      "epoch 114, valid -5.1629e-01\n",
      "epoch 115, valid -5.1653e-01\n",
      "epoch 116, valid -5.1668e-01\n",
      "epoch 117, valid -5.1666e-01\n",
      "epoch 118, valid -5.1655e-01\n",
      "epoch 119, valid -5.1658e-01\n",
      "epoch 120, valid -5.1681e-01\n",
      "epoch 121, valid -5.1715e-01\n",
      "epoch 122, valid -5.1713e-01\n",
      "epoch 123, valid -5.1729e-01\n",
      "epoch 124, valid -5.1717e-01\n",
      "epoch 125, valid -5.1713e-01\n",
      "epoch 126, valid -5.1725e-01\n",
      "epoch 127, valid -5.1735e-01\n",
      "epoch 128, valid -5.1743e-01\n",
      "epoch 129, valid -5.1737e-01\n",
      "epoch 130, valid -5.1742e-01\n",
      "epoch 131, valid -5.1779e-01\n",
      "epoch 132, valid -5.1794e-01\n",
      "epoch 133, valid -5.1799e-01\n",
      "epoch 134, valid -5.1835e-01\n",
      "epoch 135, valid -5.1821e-01\n",
      "epoch 136, valid -5.1840e-01\n",
      "epoch 137, valid -5.1852e-01\n",
      "epoch 138, valid -5.1868e-01\n",
      "epoch 139, valid -5.1892e-01\n",
      "epoch 140, valid -5.1908e-01\n",
      "epoch 141, valid -5.1921e-01\n",
      "epoch 142, valid -5.1915e-01\n",
      "epoch 143, valid -5.1932e-01\n",
      "epoch 144, valid -5.1933e-01\n",
      "epoch 145, valid -5.1959e-01\n",
      "epoch 146, valid -5.1963e-01\n",
      "epoch 147, valid -5.1962e-01\n",
      "epoch 148, valid -5.1983e-01\n",
      "epoch 149, valid -5.1990e-01\n",
      "epoch 150, valid -5.2002e-01\n",
      "epoch 151, valid -5.2009e-01\n",
      "epoch 152, valid -5.2024e-01\n",
      "epoch 153, valid -5.2032e-01\n",
      "epoch 154, valid -5.2043e-01\n",
      "epoch 155, valid -5.2052e-01\n",
      "epoch 156, valid -5.2058e-01\n",
      "epoch 157, valid -5.2072e-01\n",
      "epoch 158, valid -5.2079e-01\n",
      "epoch 159, valid -5.2080e-01\n",
      "epoch 160, valid -5.2094e-01\n",
      "epoch 161, valid -5.2097e-01\n",
      "epoch 162, valid -5.2105e-01\n",
      "epoch 163, valid -5.2109e-01\n",
      "epoch 164, valid -5.2114e-01\n",
      "epoch 165, valid -5.2105e-01\n",
      "epoch 166, valid -5.2104e-01\n",
      "epoch 167, valid -5.2110e-01\n",
      "epoch 168, valid -5.2111e-01\n",
      "epoch 169, valid -5.2106e-01\n",
      "epoch 170, valid -5.2115e-01\n",
      "epoch 171, valid -5.2093e-01\n",
      "epoch 172, valid -5.2100e-01\n",
      "epoch 173, valid -5.2091e-01\n",
      "epoch 174, valid -5.2094e-01\n",
      "epoch 175, valid -5.2081e-01\n",
      "epoch 176, valid -5.2104e-01\n",
      "epoch 177, valid -5.2098e-01\n",
      "epoch 178, valid -5.2089e-01\n",
      "epoch 179, valid -5.2091e-01\n",
      "epoch 180, valid -5.2093e-01\n",
      "epoch 181, valid -5.2119e-01\n",
      "epoch 182, valid -5.2120e-01\n",
      "epoch 183, valid -5.2143e-01\n",
      "epoch 184, valid -5.2145e-01\n",
      "epoch 185, valid -5.2159e-01\n",
      "epoch 186, valid -5.2145e-01\n",
      "epoch 187, valid -5.2151e-01\n",
      "epoch 188, valid -5.2180e-01\n",
      "epoch 189, valid -5.2175e-01\n",
      "epoch 190, valid -5.2187e-01\n",
      "epoch 191, valid -5.2186e-01\n",
      "epoch 192, valid -5.2182e-01\n",
      "epoch 193, valid -5.2195e-01\n",
      "epoch 194, valid -5.2198e-01\n",
      "epoch 195, valid -5.2199e-01\n",
      "epoch 196, valid -5.2193e-01\n",
      "epoch 197, valid -5.2203e-01\n",
      "epoch 198, valid -5.2193e-01\n",
      "epoch 199, valid -5.2202e-01\n",
      "Final cost:  -0.5220238907435021\n",
      "Performance improvement: 24.68 % over baseline cost\n"
     ]
    }
   ],
   "source": [
    "# Perform training\n",
    "time_horizon = 10\n",
    "epochs = 200\n",
    "batch_size = 5\n",
    "lr = 0.05\n",
    "\n",
    "# Initialize value function V(x) = x'Px + q'x\n",
    "# centered at h_max/2 (between 0 and h_max) of each node\n",
    "torch.manual_seed(0)\n",
    "P_sqrt = torch.eye(n, requires_grad=True, dtype=torch.double)\n",
    "q = -h_max * torch.ones(n, 1, dtype=torch.double)\n",
    "# P_sqrt = torch.zeros(n, n).double()\n",
    "# q = torch.zeros((n, 1)).double()\n",
    "q.requires_grad_(True)\n",
    "params = [P_sqrt, q]\n",
    "\n",
    "# Baseline\n",
    "P_sqrt_baseline = torch.eye(n, dtype=torch.double)\n",
    "q_baseline = -h_max * torch.ones(n, 1, dtype=torch.double)\n",
    "# P_sqrt_baseline = torch.zeros(n, n).double()\n",
    "# q_baseline = torch.zeros((n, 1)).double()\n",
    "baseline_params = [P_sqrt_baseline, q_baseline]\n",
    "baseline_costs, x_behav_bl, u_behav_bl = monte_carlo(policy, baseline_params, time_horizon, batch_size=1, trials=10, seed=0)\n",
    "baseline_cost = np.mean(baseline_costs)\n",
    "print(\"Baseline cost: \", baseline_cost)\n",
    "\n",
    "print(\"Perform training\")\n",
    "val_cost, params, x_behav, u_behav = train(policy, params, time_horizon, lr, epochs, batch_size)\n",
    "print(\"Final cost: \", val_cost[-1])\n",
    "\n",
    "improvement = 100 * np.abs(baseline_cost - val_cost[-1])/np.abs(baseline_cost)\n",
    "print(\"Performance improvement: %.2f %% over baseline cost\" %  improvement)\n",
    "\n",
    "# Store final values\n",
    "P_sqrt_train = P_sqrt.detach().numpy()\n",
    "q_train = q.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_cost, c='k', label=\"Loss\")\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('cost')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"supply_chain_training.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[1.4888],\n",
       "          [2.3047],\n",
       "          [0.2654],\n",
       "          [0.3961],\n",
       "          [0.6468],\n",
       "          [1.2382],\n",
       "          [0.8050],\n",
       "          [1.1278]]], dtype=torch.float64),\n",
       " tensor([[[1.1766],\n",
       "          [1.1766],\n",
       "          [1.1516],\n",
       "          [1.1516],\n",
       "          [1.0840],\n",
       "          [1.3068],\n",
       "          [0.8660],\n",
       "          [1.3762]]], dtype=torch.float64)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_behav[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
