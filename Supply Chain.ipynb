{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import scipy.sparse as spa\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# generate problem data\n",
    "n = 4   # nodes\n",
    "k = 2   # suppliers (with prices p)\n",
    "c = 2   # retail (with demand d)\n",
    "m = 8   # links\n",
    "\n",
    "supply_links = [0, 1]\n",
    "retail_links = [6, 7]\n",
    "internode_links = [2, 3, 4, 5]\n",
    "\n",
    "# Incidence matrices (nodes x links)\n",
    "A_in = np.array([[1, 0, 0, 0, 0, 0, 0, 0],   # 1 (supply)\n",
    "                 [0, 1, 0, 0, 0, 0, 0, 0],   # 2 (supply)\n",
    "                 [0, 0, 1, 0, 0, 1, 0, 0],   # 3 (retail)\n",
    "                 [0, 0, 0, 1, 1, 0, 0, 0],   # 4 (retail)\n",
    "                 ])\n",
    "\n",
    "A_out = np.array([[0, 0, 1, 1, 0, 0, 0, 0],   # 1 (supply)\n",
    "                  [0, 0, 0, 0, 1, 0, 0, 0],   # 2 (supply)\n",
    "                  [0, 0, 0, 0, 0, 0, 1, 0],   # 3 (retail)\n",
    "                  [0, 0, 0, 0, 0, 1, 0, 1],   # 4 (retail)\n",
    "                  ])\n",
    "\n",
    "# Prices\n",
    "mu_p = torch.tensor([0, 0.1]).double()\n",
    "sigma_p = torch.tensor([0.2, 0.2]).double()\n",
    "mean_p = torch.exp(mu_p + sigma_p ** 2 /2).double().view(k, 1)\n",
    "var_p = (torch.exp(sigma_p ** 2) - 1) * torch.exp(2 * mean_p + sigma_p ** 2)\n",
    "\n",
    "# Demands\n",
    "mu_d = torch.tensor([0.0, 0.4]).double()\n",
    "sigma_d = torch.tensor([0.2, 0.2]).double()\n",
    "mean_d = torch.exp(mu_d + sigma_d ** 2 /2).double().view(c, 1)\n",
    "var_d = (torch.exp(sigma_d ** 2) - 1) * torch.exp(2 * mean_d + sigma_d ** 2)\n",
    "\n",
    "# Uncertainty distribution (prices and demands)\n",
    "w_dist = torch.distributions.log_normal.LogNormal(torch.cat([mu_p, mu_d], 0), \n",
    "                                                  torch.cat([sigma_p, sigma_d], 0))\n",
    "\n",
    "# Capacities\n",
    "h_max = 3. # Maximum capacity in every node\n",
    "u_max = 2. # Link flow capacity\n",
    "\n",
    "# Storage cost parameters, W(x) = alpha'x + beta'x^2 + gamma\n",
    "alpha = 0.01\n",
    "beta = 0.01\n",
    "\n",
    "# Transportation cost parameters\n",
    "tau = 0.05 * np.ones((m - k - c, 1))\n",
    "tau_th = torch.tensor(tau, dtype=torch.double)\n",
    "r = 1.3 * np.ones((k, 1))\n",
    "r_th = torch.tensor(r, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1414, 1.1658, 1.0124, 1.6892], dtype=torch.float64)\n",
      "tensor([[1.0202],\n",
      "        [1.1275]], dtype=torch.float64)\n",
      "tensor([[0.3268, 0.3268],\n",
      "        [0.4050, 0.4050]], dtype=torch.float64)\n",
      "tensor([[1.0202],\n",
      "        [1.5220]], dtype=torch.float64)\n",
      "tensor([[0.3268, 0.3268],\n",
      "        [0.8915, 0.8915]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(w_dist.sample())\n",
    "print(mean_p)\n",
    "print(var_p)\n",
    "print(mean_d)\n",
    "print(var_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define linear dynamics\n",
    "# x = (h, p^{wh}, d) \n",
    "# u = u\n",
    "# w = (p^{wh}, d)\n",
    "# x_{t+1} = Ax_{t} + Bu_{t} + w\n",
    "A_d = np.bmat([[np.eye(n), np.zeros((n, k+c))],\n",
    "              [np.zeros((k+c, n)), np.zeros((k+c, k+c))]])\n",
    "A_d_th = torch.tensor(A_d, dtype=torch.double)\n",
    "B_d = np.vstack([A_in - A_out,\n",
    "                 np.zeros((k+c, m))])\n",
    "B_d_th = torch.tensor(B_d, dtype=torch.double)\n",
    "n_x, n_u = B_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup policy\n",
    "# Parameters\n",
    "P_sqrt = cp.Parameter((n, n)) # 4x4\n",
    "q = cp.Parameter((n, 1)) # 4x1\n",
    "x = cp.Parameter((n_x, 1)) # 8x1\n",
    "h, p, d = x[:n], x[n:n+k], x[n+k:]\n",
    "\n",
    "# Variables\n",
    "u = cp.Variable((n_u, 1))\n",
    "h_next = cp.Variable((n, 1))\n",
    "\n",
    "# Cvxpy Layer\n",
    "stage_cost = cp.vstack([p, tau, -r]).T @ u\n",
    "next_stage_cost = cp.sum_squares(P_sqrt @ h_next) + q.T @ h_next\n",
    "constraints = [h_next == h + (A_in - A_out) @ u, \n",
    "               h_next <= h_max,  \n",
    "               0 <= u, u <= u_max,\n",
    "               A_out @ u <= h, u[retail_links] <= d,\n",
    "              ]\n",
    "prob = cp.Problem(cp.Minimize(stage_cost + next_stage_cost), constraints)\n",
    "policy = CvxpyLayer(prob, [x, P_sqrt, q], [u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_cost(x, u):\n",
    "    assert x.shape[0] == u.shape[0]\n",
    "    batch_size = x.shape[0]\n",
    "    r_batch = r_th.repeat(batch_size, 1, 1)\n",
    "    tau_batch = tau_th.repeat(batch_size, 1, 1)\n",
    "    \n",
    "    h, p, dh = x[:,:n], x[:, n:n+k], x[:, n+k:]\n",
    "    \n",
    "    m = len(u)    \n",
    "    \n",
    "    # Selling + buying + shipping cost\n",
    "    s_vec = torch.cat([p, tau_batch, -r_batch], 1).double()\n",
    "    S = torch.bmm(s_vec.transpose(1, 2), u)\n",
    "    H = alpha * h + beta * (h ** 2)  # Storage cost\n",
    "        \n",
    "    return torch.sum(S, 1) + torch.sum(H, 1)\n",
    "\n",
    "def simulate(x, u):\n",
    "    assert x.shape[0] == u.shape[0]\n",
    "    batch_size = x.shape[0]\n",
    "\n",
    "    A_batch = A_d_th.repeat(batch_size, 1, 1)\n",
    "    B_batch = B_d_th.repeat(batch_size, 1, 1)\n",
    "    \n",
    "    zer = torch.zeros(batch_size, n, 1).double()\n",
    "    w = w_dist.sample((batch_size,)).double().view((batch_size, k + c, 1))\n",
    "    w_batch = torch.cat([zer, w], 1).double()\n",
    "    \n",
    "    return torch.bmm(A_batch, x) + torch.bmm(B_batch, u) + w_batch\n",
    "\n",
    "    \n",
    "def loss(policy, params, time_horizon, batch_size=1, seed=None, is_eval=True):\n",
    "    mismatch = 0.2 # mismatch parameter\n",
    "    noise = lambda input_tensor, mismatch : input_tensor if is_eval else input_tensor + mismatch * torch.randn_like(input_tensor)\n",
    "    \n",
    "    P_sqrt, q = noise(params[0], mismatch), noise(params[1], mismatch)\n",
    "    \n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "    # Batchify input\n",
    "    x_b_0 = h_max * torch.rand(batch_size, n, 1).double()\n",
    "    w_0 = w_dist.sample((batch_size,)).double().view((batch_size, k+c, 1))\n",
    "    x_batch = torch.cat([x_b_0, w_0], 1).double()\n",
    "\n",
    "    # Repeat parameter values\n",
    "    P_sqrt_batch = P_sqrt.repeat(batch_size, 1, 1)\n",
    "    q_batch = q.repeat(batch_size, 1, 1)\n",
    "\n",
    "    cost = 0.0\n",
    "    x_t = x_batch\n",
    "    x_hist = [x_batch]\n",
    "    u_hist = []\n",
    "    \n",
    "    for t in range(time_horizon):\n",
    "        u_t = policy(x_t, P_sqrt_batch, q_batch, solver_args={\"acceleration_lookback\": 0})[0]\n",
    "        x_t = simulate(x_t, u_t)\n",
    "        cost += stage_cost(x_t, u_t).mean() / time_horizon\n",
    "        x_hist.append(x_t)\n",
    "        u_hist.append(u_t)\n",
    "        \n",
    "    return cost, x_hist, u_hist\n",
    "\n",
    "def monte_carlo(policy, params, time_horizon, batch_size=1, trials=10, seed=None):\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    results = []\n",
    "    x = []\n",
    "    u = []\n",
    "    \n",
    "    for i in range(trials):\n",
    "        cost, x_hist, u_hist = loss(policy, params, time_horizon, batch_size=batch_size, seed=seed)\n",
    "        results.append(cost.item())\n",
    "        x.append(x_hist)\n",
    "        u.append(u_hist)\n",
    "    return results, x, u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(policy, params, time_horizon, lr, epochs, batch_size):\n",
    "    opt = torch.optim.SGD(params, lr=lr)\n",
    "    val_costs = []\n",
    "    best_params = []\n",
    "    # updating without gradient\n",
    "\n",
    "    with tqdm(total=epochs) as pbar:\n",
    "        for epoch in range(epochs):\n",
    "            with torch.no_grad():\n",
    "                val_cost_mc, x_behav, u_behav = monte_carlo(policy, params, time_horizon, 1, trials=10, seed=SEED)\n",
    "                val_cost = np.mean(val_cost_mc)\n",
    "                val_costs.append(val_cost)\n",
    "\n",
    "            torch.manual_seed(epoch)\n",
    "            opt.zero_grad()\n",
    "            cost, _, _,  = loss(policy, params, time_horizon, batch_size, seed=None, is_eval=False)\n",
    "            cost.backward()\n",
    "            pbar.set_description(\"epoch %d, valid %.4f\" % (epoch, val_cost))         \n",
    "\n",
    "            # TODO: Print gradient norm (possibly clip it)\n",
    "            # torch.nn.utils.clip_grad_norm_(params, 1)\n",
    "    #         for p in params:\n",
    "    #             print(p.grad.data.norm(2).item())\n",
    "            opt.step()\n",
    "    #         scheduler.step(val_cost)   \n",
    "            pbar.update(1)\n",
    "    return val_costs, [np.array(p.detach().numpy()) for p in params], x_behav, u_behav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_aggregate(policy, param_set, time_horizon, batch_size=1, seed=None):\n",
    "    costs = []\n",
    "    for param in param_set:\n",
    "        costs.append(loss(policy, params, time_horizon, batch_size=1, seed=None)[0])\n",
    "\n",
    "    best_zetas = np.argsort(costs) # update to return parameters\n",
    "    return best_zetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline cost:  0.3946889638900757\n",
      "Perform training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 44, valid 0.2312:  22%|██▎       | 45/200 [00:20<01:10,  2.19it/s]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-d24e77e51515>\", line 27, in <module>\n",
      "    val_cost, params, x_behav, u_behav = train(policy, params, time_horizon, lr, epochs, batch_size)\n",
      "  File \"<ipython-input-7-b2517ea978b1>\", line 10, in train\n",
      "    val_cost_mc, x_behav, u_behav = monte_carlo(policy, params, time_horizon, 1, trials=10, seed=SEED)\n",
      "  File \"<ipython-input-6-38cfc6490b83>\", line 72, in monte_carlo\n",
      "    cost, x_hist, u_hist = loss(policy, params, time_horizon, batch_size=batch_size, seed=seed)\n",
      "  File \"<ipython-input-6-38cfc6490b83>\", line 56, in loss\n",
      "    u_t = policy(x_t, P_sqrt_batch, q_batch, solver_args={\"acceleration_lookback\": 0})[0]\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/site-packages/cvxpylayers/torch/cvxpylayer.py\", line 152, in forward\n",
      "    sol = f(*params)\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/site-packages/cvxpylayers/torch/cvxpylayer.py\", line 289, in forward\n",
      "    As, bs, cs, cone_dicts, **solver_args)\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/site-packages/diffcp/cone_program.py\", line 83, in solve_and_derivative_batch\n",
      "    cone_dicts[i], warm_starts[i], mode=mode, **kwargs)\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/site-packages/diffcp/cone_program.py\", line 220, in solve_and_derivative\n",
      "    solve_method=solve_method, **kwargs)\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/site-packages/diffcp/cone_program.py\", line 381, in solve_and_derivative_internal\n",
      "    D_proj_dual_cone = _diffcp.dprojection(v, cones_parsed, True)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/posixpath.py\", line 385, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/Users/qasimwani/opt/anaconda3/lib/python3.7/posixpath.py\", line 359, in normpath\n",
      "    comps = path.split(sep)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Perform training\n",
    "time_horizon = 10\n",
    "epochs = 200\n",
    "batch_size = 1\n",
    "lr = 0.05\n",
    "\n",
    "# Initialize value function V(x) = x'Px + q'x\n",
    "# centered at h_max/2 (between 0 and h_max) of each node\n",
    "P_sqrt = torch.eye(n, requires_grad=True, dtype=torch.double)\n",
    "q = -h_max * torch.ones(n, 1, dtype=torch.double)\n",
    "# P_sqrt = torch.zeros(n, n).double()\n",
    "# q = torch.zeros((n, 1)).double()\n",
    "q.requires_grad_(True)\n",
    "params = [P_sqrt, q]\n",
    "\n",
    "# Baseline\n",
    "P_sqrt_baseline = torch.eye(n, dtype=torch.double)\n",
    "q_baseline = -h_max * torch.ones(n, 1, dtype=torch.double)\n",
    "# P_sqrt_baseline = torch.zeros(n, n).double()\n",
    "# q_baseline = torch.zeros((n, 1)).double()\n",
    "baseline_params = [P_sqrt_baseline, q_baseline]\n",
    "baseline_costs, x_behav_bl, u_behav_bl = monte_carlo(policy, baseline_params, time_horizon, batch_size=1, trials=10, seed=SEED)\n",
    "baseline_cost = np.mean(baseline_costs)\n",
    "print(\"Baseline cost: \", baseline_cost)\n",
    "\n",
    "print(\"Perform training\")\n",
    "val_cost, params, x_behav, u_behav = train(policy, params, time_horizon, lr, epochs, batch_size)\n",
    "print(\"Final cost: \", val_cost[-1])\n",
    "\n",
    "improvement = 100 * np.abs(baseline_cost - val_cost[-1])/np.abs(baseline_cost)\n",
    "print(\"Performance improvement: %.2f %% over baseline cost\" %  improvement)\n",
    "\n",
    "# Store final values\n",
    "P_sqrt_train = P_sqrt.detach().numpy()\n",
    "q_train = q.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_cost, c='k', label=\"Loss\")\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('cost')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"supply_chain_training.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"experiments/COCP_model_mismatch_0.2.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(path)\n",
    "    df.insert(SEED, SEED, val_cost)\n",
    "except:\n",
    "    df = pd.DataFrame(val_cost)\n",
    "\n",
    "df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
