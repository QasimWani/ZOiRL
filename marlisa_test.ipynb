{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this again after editing submodules so Colab uses the updated versions\n",
    "from citylearn import  CityLearn\n",
    "from pathlib import Path\n",
    "from agents.marlisa import MARLISA\n",
    "import numpy as np                                                                                                                                                                                      \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from utils import agent_checkpoint_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to add RBC pretrained model (sec): 30.502\n"
     ]
    }
   ],
   "source": [
    "# Load environment\n",
    "climate_zone = 1\n",
    "end_time = 8759 # total number of hours to train for\n",
    "cost_analysis = 24 # analyze costs every x hours\n",
    "checkpoint = 24 * 7 # save parameters every x hours\n",
    "\n",
    "params = {'data_path':Path(\"data/Climate_Zone_\"+str(climate_zone)), \n",
    "        'building_attributes':'building_attributes.json', \n",
    "        'weather_file':'weather_data.csv', \n",
    "        'solar_profile':'solar_generation_1kW.csv', \n",
    "        'carbon_intensity':'carbon_intensity.csv',\n",
    "        'building_ids':[\"Building_\"+str(i) for i in [1,2,3,4,5,6,7,8,9]],\n",
    "        'buildings_states_actions':'buildings_state_action_space.json', \n",
    "        'simulation_period': (0, end_time), \n",
    "        'cost_function': ['ramping','1-load_factor','average_daily_peak','peak_demand','net_electricity_consumption','carbon_emissions'], \n",
    "        'central_agent': False,\n",
    "        'cost_analysis' : cost_analysis,\n",
    "        'save_memory': False }\n",
    "\n",
    "# Contain the lower and upper bounds of the states and actions, to be provided to the agent to normalize the variables between 0 and 1.\n",
    "env = CityLearn(**params)\n",
    "env.pretrain_baseline_model((0, end_time))\n",
    "\n",
    "observations_spaces, actions_spaces = env.get_state_action_spaces()\n",
    "\n",
    "# Provides information on Building type, Climate Zone, Annual DHW demand, Annual Cooling Demand, Annual Electricity Demand, Solar Capacity, and correllations among buildings\n",
    "building_info = env.get_building_information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cost: 1.01: 100%|██████████| 8759/8759 [1:28:57<00:00,  1.64it/s] \n"
     ]
    }
   ],
   "source": [
    "params_agent = {'building_ids':[\"Building_\"+str(i) for i in [1,2,3,4,5,6,7,8,9]],\n",
    "                 'buildings_states_actions':'buildings_state_action_space.json', \n",
    "                 'building_info':building_info,\n",
    "                 'observation_spaces':observations_spaces, \n",
    "                 'action_spaces':actions_spaces, \n",
    "                 'hidden_dim':[256,256], \n",
    "                 'discount':0.99, \n",
    "                 'tau':5e-3, \n",
    "                 'lr':3e-4, \n",
    "                 'batch_size':256, \n",
    "                 'replay_buffer_capacity':1e5, \n",
    "                 'regression_buffer_capacity':3e4, \n",
    "                 'start_training':600, # Start updating actor-critic networks\n",
    "                 'exploration_period':7500, # Just taking random actions\n",
    "                 'start_regression':500, # Start training the regression model\n",
    "                 'information_sharing':True, # If True -> set the appropriate 'reward_function_ma' in reward_function.py\n",
    "                 'pca_compression':.95, \n",
    "                 'action_scaling_coef':0.5, # Actions are multiplied by this factor to prevent too aggressive actions\n",
    "                 'reward_scaling':5., # Rewards are normalized and multiplied by this factor\n",
    "                 'update_per_step':2, # How many times the actor-critic networks are updated every hourly time-step\n",
    "                 'iterations_as':2,# Iterations of the iterative action selection (see MARLISA paper for more info)\n",
    "                 'safe_exploration':True} \n",
    "\n",
    "# Instantiating the control agent(s)\n",
    "agents = MARLISA(**params_agent)\n",
    "\n",
    "# We will use 1 episode if we intend to simulate a real-time RL controller (like in the CityLearn Challenge)\n",
    "# In climate zone 5, 1 episode contains 5 years of data, or 8760*5 time-steps.\n",
    "n_episodes = 1\n",
    "start = time.time()\n",
    "for e in range(n_episodes): \n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    j = 0\n",
    "    is_evaluating = False\n",
    "    action, coordination_vars = agents.select_action(state, deterministic=is_evaluating)    \n",
    "    with tqdm(total=end_time) as pbar:\n",
    "        while not done:\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            action_next, coordination_vars_next = agents.select_action(next_state, deterministic=is_evaluating)\n",
    "            agents.add_to_buffer(state, action, reward, next_state, done, coordination_vars, coordination_vars_next)\n",
    "            coordination_vars = coordination_vars_next\n",
    "            state = next_state\n",
    "            action = action_next\n",
    "\n",
    "            is_evaluating = (j > 3*8760)\n",
    "            j += 1\n",
    "            pbar.update(1)\n",
    "            try:\n",
    "                pbar.set_description(f\"Cost: {round(env.costs_periodic[-1]['total'], 3)}\")\n",
    "            except:\n",
    "                pass\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"marlisa_data.npy\", env.costs_periodic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
