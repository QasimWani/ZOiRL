{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qasimwani/Desktop/research/RL/CityLearn/ROLEVT/actor.py:909: DeprecationWarning: invalid escape sequence \\d\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.9/site-packages/diffcp/cones.py:7: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if StrictVersion(scs.__version__) >= StrictVersion('3.0.0'):\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"always\")\n",
    "\n",
    "# Run this again after editing submodules so Colab uses the updated versions\n",
    "from citylearn import  CityLearn\n",
    "from pathlib import Path\n",
    "from TD3 import Agent as Agent\n",
    "import numpy as np                                                                                                                                                                                      \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from utils import agent_checkpoint_cost\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to add RBC pretrained model (sec): 1.805\n"
     ]
    }
   ],
   "source": [
    "# Load environment\n",
    "climate_zone = 1\n",
    "end_time = 1000 # total number of hours to train for\n",
    "cost_analysis = 24 # analyze costs every x hours\n",
    "checkpoint = 24 * 7 # save parameters every x hours\n",
    "\n",
    "params = {'data_path':Path(\"data/Climate_Zone_\"+str(climate_zone)), \n",
    "        'building_attributes':'building_attributes.json', \n",
    "        'weather_file':'weather_data.csv', \n",
    "        'solar_profile':'solar_generation_1kW.csv', \n",
    "        'carbon_intensity':'carbon_intensity.csv',\n",
    "        'building_ids':[\"Building_\"+str(i) for i in [1,2,3,4,5,6,7,8,9]],\n",
    "        'buildings_states_actions':'buildings_state_action_space.json', \n",
    "        'simulation_period': (0, end_time), \n",
    "        'cost_function': ['ramping','1-load_factor','average_daily_peak','peak_demand','net_electricity_consumption','carbon_emissions'], \n",
    "        'central_agent': False,\n",
    "        'cost_analysis' : cost_analysis,\n",
    "        'save_memory': False }\n",
    "\n",
    "# Contain the lower and upper bounds of the states and actions, to be provided to the agent to normalize the variables between 0 and 1.\n",
    "env = CityLearn(**params)\n",
    "env.pretrain_baseline_model((0, end_time))\n",
    "\n",
    "observations_spaces, actions_spaces = env.get_state_action_spaces()\n",
    "\n",
    "# Provides information on Building type, Climate Zone, Annual DHW demand, Annual Cooling Demand, Annual Electricity Demand, Solar Capacity, and correllations among buildings\n",
    "building_info = env.get_building_information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse_critic():\n",
    "    if not agent.did_i_just_finish_training():\n",
    "            return None, None\n",
    "    try:\n",
    "        data = {}\n",
    "        NUM_DAYS = len(agent.critic_optim.debug['ramping_cost'])\n",
    "\n",
    "        for key, _d in agent.critic_optim.debug.items():\n",
    "            data[key] = []\n",
    "            for day in _d:\n",
    "                data[key].append(day.value)\n",
    "            data[key] = np.reshape(data[key], (NUM_DAYS * 24))\n",
    "\n",
    "        rc = data['ramping_cost']\n",
    "        peak = data['peak_net_electricity_cost']\n",
    "        ec = data['electricity_cost']\n",
    "\n",
    "        A = np.vstack((-rc, -peak)).T\n",
    "        y = np.reshape(agent.critic_optim.problem.param_dict['y_r'].value, (NUM_DAYS * 24))\n",
    "\n",
    "        x, residuals, rank, s = np.linalg.lstsq(A, y, rcond=None)\n",
    "        # print(f\"Rank: {rank}\\tCondition Number: {np.linalg.cond(A)}\")\n",
    "        # print(f\"MSE across {NUM_DAYS} days: {round(np.linalg.norm(A@x - y), 5)}\")\n",
    "        return round(np.linalg.norm(A@x - y), 5), round(np.linalg.cond(A), 3)\n",
    "    except:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cost: 1.42689:  43%|██████████▊              | 430/1000 [00:24<01:21,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Optim\tBuilding: 0\tHour: 23\u001b[H\u001b[2J"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Cost: 1.42689:  43%|██████████▊              | 431/1000 [02:08<02:49,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Solving L2 optimization using SCS solver for building 0\u001b[H\u001b[2J"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Unbounded solution/primal infeasable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSolverError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/research/RL/CityLearn/ROLEVT/critic.py:1030\u001b[0m, in \u001b[0;36mOptim.least_absolute_optimization\u001b[0;34m(self, parameters, zeta_target, building_id, critic_target, is_random, debug)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1030\u001b[0m     optim_solution \u001b[38;5;241m=\u001b[39m \u001b[43mprob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# max_iters=1_000_000\u001b[39;49;00m\n\u001b[1;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# eps=1e-2,  # tolerance\u001b[39;49;00m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Returns the optimal value.\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m<\u001b[39m optim_solution \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1036\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization failed! Trying SCS...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/cvxpy/problems/problem.py:481\u001b[0m, in \u001b[0;36mProblem.solve\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m     solve_func \u001b[38;5;241m=\u001b[39m Problem\u001b[38;5;241m.\u001b[39m_solve\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msolve_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/cvxpy/problems/problem.py:1016\u001b[0m, in \u001b[0;36mProblem._solve\u001b[0;34m(self, solver, warm_start, verbose, gp, qcp, requires_grad, enforce_dpp, ignore_dpp, **kwargs)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solve_time \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n\u001b[0;32m-> 1016\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolving_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/cvxpy/problems/problem.py:1341\u001b[0m, in \u001b[0;36mProblem.unpack_results\u001b[0;34m(self, solution, chain, inverse_data)\u001b[0m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solution\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m s\u001b[38;5;241m.\u001b[39mERROR:\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mSolverError(\n\u001b[1;32m   1342\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolver \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m failed. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m chain\u001b[38;5;241m.\u001b[39msolver\u001b[38;5;241m.\u001b[39mname() \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m   1343\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry another solver, or solve with verbose=True for more \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1344\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minformation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munpack(solution)\n",
      "\u001b[0;31mSolverError\u001b[0m: Solver 'OSQP' failed. Try another solver, or solve with verbose=True for more information.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m action, _ \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mselect_action(state)\n\u001b[1;32m     26\u001b[0m next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m---> 27\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_to_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[1;32m     30\u001b[0m rewards\u001b[38;5;241m.\u001b[39mappend(reward)\n",
      "File \u001b[0;32m~/Desktop/research/RL/CityLearn/ROLEVT/TD3.py:281\u001b[0m, in \u001b[0;36mTD3.add_to_buffer\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_it \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_episode \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m24\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# and self.total_it >= self.rbc_threshold + self.meta_episode * 24\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory)\n\u001b[1;32m    279\u001b[0m ):\n\u001b[1;32m    280\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    283\u001b[0m     LOG(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime taken for training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(end \u001b[38;5;241m-\u001b[39m start, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/research/RL/CityLearn/ROLEVT/TD3.py:247\u001b[0m, in \u001b[0;36mTD3.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    242\u001b[0m rewards_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward_memory\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    243\u001b[0m     sample_by_indices\u001b[38;5;241m=\u001b[39midx_2\n\u001b[1;32m    244\u001b[0m )  \u001b[38;5;66;03m# critic 2 - rewards part\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# local + target critic update\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards_1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards_2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# local + target actor update\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_update(parameters_1)\n",
      "File \u001b[0;32m~/Desktop/research/RL/CityLearn/ROLEVT/TD3.py:191\u001b[0m, in \u001b[0;36mTD3.critic_update\u001b[0;34m(self, params_1, params_2)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Local Critic Update\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuildings, TEMP_VAR)):\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;66;03m# local critic backward pass\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic_optim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mday_params_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mday_params_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_target\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# Target Critic update - moving average\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_target)):\n",
      "File \u001b[0;32m~/Desktop/research/RL/CityLearn/ROLEVT/critic.py:1084\u001b[0m, in \u001b[0;36mOptim.backward\u001b[0;34m(self, batch_parameters_1, batch_parameters_2, zeta_target, building_id, critic_local, critic_target, debug)\u001b[0m\n\u001b[1;32m   1082\u001b[0m critic_local_1, critic_local_2 \u001b[38;5;241m=\u001b[39m critic_local\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;66;03m# Compute L2 Optimization for Critic Local 1 (using sequential data) and Critic Local 2 (using random data) using Critic Target 1 and 2\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m local_1_solution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleast_absolute_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_parameters_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_parameters_2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzeta_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuilding_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcritic_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;66;03m# local_2_solution = self.least_absolute_optimization(\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;66;03m#     (batch_parameters_2, batch_parameters_1),\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;66;03m#     zeta_target,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;66;03m# update alphas for local\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m critic_local_1\u001b[38;5;241m.\u001b[39malpha_ramp[building_id] \u001b[38;5;241m=\u001b[39m local_1_solution[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mramp\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/research/RL/CityLearn/ROLEVT/critic.py:1051\u001b[0m, in \u001b[0;36mOptim.least_absolute_optimization\u001b[0;34m(self, parameters, zeta_target, building_id, critic_target, is_random, debug)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     LOG(\n\u001b[1;32m   1043\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSolving L2 optimization using SCS solver for building \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbuilding_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1044\u001b[0m     )\n\u001b[1;32m   1046\u001b[0m     optim_solution \u001b[38;5;241m=\u001b[39m prob\u001b[38;5;241m.\u001b[39msolve(\n\u001b[1;32m   1047\u001b[0m         solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCS\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1048\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mdebug,  \u001b[38;5;66;03m# max_iters=1_000_000\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m     )  \u001b[38;5;66;03m# Returns the optimal value.\u001b[39;00m\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m   1052\u001b[0m         \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m<\u001b[39m optim_solution \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1053\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnbounded solution/primal infeasable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;66;03m# Make sure resultant Q-value is negative for all hours\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(prob\u001b[38;5;241m.\u001b[39mconstraints)):\n",
      "\u001b[0;31mAssertionError\u001b[0m: Unbounded solution/primal infeasable"
     ]
    }
   ],
   "source": [
    "params_agent = {'building_ids':[\"Building_\"+str(i) for i in [1,2,3,4,5,6,7,8,9]],\n",
    "                 'buildings_states_actions':'buildings_state_action_space.json', \n",
    "                 'building_info':building_info,\n",
    "                 'observation_spaces':observations_spaces,\n",
    "                 'agent_checkpoint' : checkpoint,\n",
    "                 'action_spaces':actions_spaces}\n",
    "\n",
    "# Instantiating the control agent(s)\n",
    "rewards = []\n",
    "critic_mse = [] # only last building to be added MSE will be recorded\n",
    "\n",
    "agent = Agent(**params_agent)\n",
    "\n",
    "state = env.reset()\n",
    "done = False\n",
    "\n",
    "with tqdm(total=end_time) as pbar:\n",
    "    while not done:\n",
    "        \n",
    "        # get agent\n",
    "        # day_type = env.buildings['Building_1'].sim_results['day'][env.time_step]\n",
    "        # agent = agents.get_agent(day_type)\n",
    "        # get agent\n",
    "        \n",
    "        action, _ = agent.select_action(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.add_to_buffer(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "\n",
    "        rewards.append(reward)\n",
    "\n",
    "        try:\n",
    "            mse, condition = get_mse_critic()\n",
    "            txt = f\"Cost: {round(env.costs_periodic[-1]['total'], 5)}\"\n",
    "            if len(critic_mse) > 0:\n",
    "                txt += f\"\\tCritic MSE: {critic_mse[-1][0]}\\tCondition number: {critic_mse[-1][1]}\"\n",
    "                \n",
    "            if mse is not None:\n",
    "                critic_mse.append([mse, condition])\n",
    "                \n",
    "            pbar.set_description(txt)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "rewards = np.array(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.critic_target[0].debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=23\n",
    "agent.critic[0].prob[i].solve('SCS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.critic[0].prob[i].solve('SCS', eps=5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = agent.critic[0].prob[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-r * ramping_cost - electricity_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.solve(solver='SCS', max_iters=10_000_000, eps=5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(e[t:] * E_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_type = 0\n",
    "Q_value, ramping_cost, peak_hist_cost, electricity_cost, E_grid, E_grid_true, E_grid_prevhour, (bid, t) = agent.critic_target[_type].debug\n",
    "r, e = agent.critic[_type].alpha_ramp[bid], agent.critic[_type].alpha_elec[bid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(agent.actor._grads[0]['p_ele_grad'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.array(critic_mse)[:, 0])\n",
    "plt.xlabel(\"Meta-episode #\")\n",
    "plt.ylabel(\"Cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.actor.debug[1][\"E_grid_prevhour\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(rewards)[23:, 0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(critic_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in agent.actor._losses.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(rewards).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = [x[\"total\"] for x in env.costs_periodic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(agent.actor._grads[0]['p_ele_grad'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.cost_detailed_view()['Building_1']['cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.cost((0, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "NUM_DAYS = len(agent.critic_optim.debug['ramping_cost'])\n",
    "\n",
    "for key, _d in agent.critic_optim.debug.items():\n",
    "    data[key] = []\n",
    "    for day in _d:\n",
    "        data[key].append(day.value)\n",
    "    data[key] = np.reshape(data[key], (NUM_DAYS * 24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = data['ramping_cost']\n",
    "peak = data['peak_net_electricity_cost']\n",
    "ec = data['electricity_cost']\n",
    "\n",
    "A = np.vstack((-rc, -peak**2)).T\n",
    "y = np.reshape(agent.critic_optim.problem.param_dict['y_r'].value, (NUM_DAYS * 24))\n",
    "\n",
    "x, residuals, rank, s = np.linalg.lstsq(A, y, rcond=None)\n",
    "print(f\"Rank: {rank}\\tCondition Number: {np.linalg.cond(A)}\")\n",
    "print(f\"MSE across {NUM_DAYS} days: {round(np.linalg.norm(A@x - y), 5)}\")\n",
    "\n",
    "plt.plot(A@x, label='y_hat')\n",
    "plt.plot(y, label='y')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Hours\")\n",
    "plt.ylabel(\"Q-value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(A@x).max(), y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = agent.critic_optim.problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy\n",
    "for i in range(len(p.constraints)):\n",
    "    x = p.constraints[i]\n",
    "    if isinstance(x.args[0], cvxpy.atoms.affine.add_expr.AddExpression):\n",
    "        assert x.args[0].value <= 1, (i, x.args[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.critic_target[0].alpha_peak1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.critic_optim.debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(agent.critic[0].alpha_elec, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.critic_target[0].alpha_ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.critic[0].alpha_ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_t = np.array(agent._actor_zetas['p_ele_local']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(24), agent.actor.zeta['p_ele'][:, 0], c='k', label=\"Iteration 3\")\n",
    "plt.bar(range(24), _t[0, :, 0], label=\"Initial\")\n",
    "plt.bar(range(24), _t[0, :, 1], label=\"Iteration 1\")\n",
    "plt.bar(range(24), _t[0, :, 2], label=\"Iteration 2\")\n",
    "plt.legend(loc=\"upper center\", bbox_to_anchor=(0.5, 1.15), ncol=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seaborn plotting aesthetics as default\n",
    "sns.set(rc={'figure.figsize':(5,5)})\n",
    "df = np.array(agent._actor_zetas['p_ele_local'])\n",
    "df = np.append(df, np.expand_dims(agent.actor.zeta['p_ele'], 0)).reshape((9, 24, 9)).T\n",
    "\n",
    "fig, axn = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "cbar_ax = fig.add_axes([.91, .3, .03, .4])\n",
    "\n",
    "for i, ax in enumerate(axn.flat):\n",
    "    sns.heatmap(df[i], ax=ax,\n",
    "                cbar=i == 0,\n",
    "                cmap='viridis',\n",
    "                cbar_ax=None if i else cbar_ax)\n",
    "    ax.set(title=f\"Building {i + 1}\")\n",
    "\n",
    "axn.flat[0].set(ylabel='Hour of Day')\n",
    "axn.flat[2].set(ylabel='Hour of Day')\n",
    "axn.flat[2].set(xlabel='Month')\n",
    "axn.flat[3].set(xlabel='Month')\n",
    "\n",
    "\n",
    "fig.tight_layout(rect=[0, 0, .9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(24), agent.actor.zeta['p_ele'][:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(agent._actor_zetas[\"p_ele_local\"])[:, :, 0].min(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(agent._actor_zetas[\"p_ele_target\"])[:, :, 0].min(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.actor.scs_cnt, agent.actor.fail_cnt, agent.critic_optim.fail_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.actor.zeta[\"p_ele\"][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.critic[0].alpha_peak1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.critic_target[0].alpha_peak1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.actor.zeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
