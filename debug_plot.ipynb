{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this again after editing submodules so Colab uses the updated versions\n",
    "\n",
    "from copy import deepcopy\n",
    "from citylearn import CityLearn\n",
    "from pathlib import Path\n",
    "\n",
    "from TD3 import TD3 as Agent\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "import utils\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Load environment\n",
    "climate_zone = 5\n",
    "params = {\n",
    "    \"data_path\": Path(\"data/Climate_Zone_\" + str(climate_zone)),\n",
    "    \"building_attributes\": \"building_attributes.json\",\n",
    "    \"weather_file\": \"weather_data.csv\",\n",
    "    \"solar_profile\": \"solar_generation_1kW.csv\",\n",
    "    \"carbon_intensity\": \"carbon_intensity.csv\",\n",
    "    \"building_ids\": [\"Building_\" + str(i) for i in [1, 2, 3, 4, 5, 6, 7, 8, 9]],\n",
    "    \"buildings_states_actions\": \"buildings_state_action_space.json\",\n",
    "    \"simulation_period\": (0, 8760 * 4 - 1),\n",
    "    \"cost_function\": [\n",
    "        \"ramping\",\n",
    "        \"1-load_factor\",\n",
    "        \"average_daily_peak\",\n",
    "        \"peak_demand\",\n",
    "        \"net_electricity_consumption\",\n",
    "        \"carbon_emissions\",\n",
    "    ],\n",
    "    \"central_agent\": False,\n",
    "    \"save_memory\": False,\n",
    "}\n",
    "\n",
    "# Contain the lower and upper bounds of the states and actions, to be provided to the agent to normalize the variables between 0 and 1.\n",
    "env = CityLearn(**params)\n",
    "observations_spaces, actions_spaces = env.get_state_action_spaces()\n",
    "\n",
    "# Provides information on Building type, Climate Zone, Annual DHW demand, Annual Cooling Demand, Annual Electricity Demand, Solar Capacity, and correllations among buildings\n",
    "building_info = env.get_building_information()\n",
    "\n",
    "# Parameters for the agent\n",
    "params_agent = {\n",
    "    \"building_ids\": [\"Building_\" + str(i) for i in [1, 2, 3, 4, 5, 6, 7, 8, 9]],\n",
    "    \"buildings_states_actions\": \"buildings_state_action_space.json\",\n",
    "    \"building_info\": building_info,\n",
    "    \"observation_spaces\": observations_spaces,\n",
    "    \"action_spaces\": actions_spaces,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step: 95"
     ]
    }
   ],
   "source": [
    "env = CityLearn(**params)\n",
    "observations_spaces, actions_spaces = env.get_state_action_spaces()\n",
    "\n",
    "# Provides information on Building type, Climate Zone, Annual DHW demand, Annual Cooling Demand, Annual Electricity Demand, Solar Capacity, and correllations among buildings\n",
    "building_info = env.get_building_information()\n",
    "\n",
    "\n",
    "params_agent = {\n",
    "    \"building_ids\": [\"Building_\" + str(i) for i in [1, 2, 3, 4, 5, 6, 7, 8, 9]],\n",
    "    \"buildings_states_actions\": \"buildings_state_action_space.json\",\n",
    "    \"building_info\": building_info,\n",
    "    \"observation_spaces\": observations_spaces,\n",
    "    \"action_spaces\": actions_spaces,\n",
    "}\n",
    "\n",
    "# Instantiating the control agent(s)\n",
    "# agents = Agent(**params_agent)\n",
    "RBC_THRESHOLD = 48  # 2 weeks\n",
    "agents = Agent(\n",
    "    num_actions=actions_spaces,\n",
    "    num_buildings=len(observations_spaces),\n",
    "    env=env,\n",
    "    rbc_threshold=RBC_THRESHOLD,\n",
    ")\n",
    "\n",
    "# Initialising variables for the RL agent, RBC controller and NO_RL agent\n",
    "# 1. RBC Agent\n",
    "RBC_actions_arr = []\n",
    "RBC_look_ahead_cost = []  \n",
    "RBC_E_grid_pred = []\n",
    "RBC_E_hpC = []\n",
    "RBC_E_ehH = []\n",
    "RBC_Edhw = []\n",
    "RBC_SOC_bat = []\n",
    "RBC_SOC_C = []\n",
    "RBC_SOC_H = []\n",
    "RBC_C_p_bat = []\n",
    "RBC_C_p_Csto = []\n",
    "RBC_C_p_Hsto = []\n",
    "RBC_ramping_cost = []\n",
    "RBC_peak_electricity_cost = []\n",
    "RBC_total_cost = []\n",
    "RBC_action_C = []\n",
    "RBC_action_H = []\n",
    "RBC_action_bat = []\n",
    "\n",
    "# 2. RL Agent\n",
    "RL_actions_arr = []\n",
    "RL_look_ahead_cost = []  \n",
    "RL_E_grid_pred = []\n",
    "RL_E_hpC = []\n",
    "RL_E_ehH = []\n",
    "RL_Edhw = []\n",
    "RL_SOC_bat = []\n",
    "RL_SOC_H = []\n",
    "RL_C_p_bat = []\n",
    "RL_C_p_Csto = []\n",
    "RL_C_p_Hsto = []\n",
    "RL_ramping_cost = []\n",
    "RL_peak_electricity_cost = []\n",
    "RL_total_cost = []\n",
    "RL_action_C = []\n",
    "RL_action_H = []\n",
    "RLaction_bat = []\n",
    "\n",
    "# 3. NO RL Agent (Just Optimization)\n",
    "NORL_actions_arr = []\n",
    "NORL_look_ahead_cost = []\n",
    "Egrid = []  \n",
    "NORL_E_grid_pred = []\n",
    "NORL_E_hpC = []\n",
    "NORL_E_ehH = []\n",
    "NORL_Edhw = []\n",
    "NORL_SOC_bat = []\n",
    "NORL_SOC_C = []\n",
    "NORL_SOC_H = []\n",
    "NORL_C_p_bat = []\n",
    "NORL_C_p_Csto = []\n",
    "NORL_C_p_Hsto = []\n",
    "NORL_ramping_cost = []\n",
    "NORL_peak_electricity_cost = []\n",
    "NORL_total_cost = []\n",
    "NORL_action_C = []\n",
    "NORL_action_H = []\n",
    "NORL_action_bat = []\n",
    "\n",
    "# Initialising the simulation for all the agents\n",
    "state = env.reset()\n",
    "done = False\n",
    "\n",
    "action = agents.select_action(state)\n",
    "\n",
    "t_idx = 0\n",
    "# run for a month - NOTE: THIS WILL TAKE ~2 HOURS TO RUN. reduce `end_time` for quicker results.\n",
    "end_time = RBC_THRESHOLD + 24 * 7\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "costs_peak_net_ele = []\n",
    "\n",
    "# returns E_grid for RBC agent\n",
    "E_grid_RBC = utils.RBC(actions_spaces).get_rbc_data(\n",
    "    deepcopy(env), state, utils.get_idx_hour(), end_time)\n",
    "\n",
    "E_grid_true = []  # see comments below for more info.\n",
    "\n",
    "while not done and t_idx <= end_time:\n",
    "\n",
    "    ## add env E-grid\n",
    "    E_grid_true.append([x[28] for x in state])\n",
    "\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    action_next = agents.select_action(\n",
    "        next_state, env\n",
    "    )  # passing in environment for Oracle agent.\n",
    "\n",
    "    agents.add_to_buffer_oracle(env, action, reward)\n",
    "    # agents.add_to_buffer(state, action, reward, next_state, done)\n",
    "    state = next_state\n",
    "    action = action_next\n",
    "\n",
    "    t_idx += 1\n",
    "\n",
    "    print(f\"\\rTime step: {t_idx}\", end=\"\")\n",
    "\n",
    "print(\n",
    "    f\"Total time (min) to run {end_time // 24} days of simulation: {round((time.time() - start_time) / 60, 3)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## TODO: ENTER CODE HERE ##############\n",
    "\n",
    "# list of dictionary of variables generated from RL. See actor.py#L166 for relevant variable names. eg. vars_RL[0]['E_grid']\n",
    "# NOTE: dimensions of RL/NORL logger is â‰  RBC. This is because RL/NORL implicitly uses RBC. We only start collecting data from\n",
    "# RL/NORL once it starts making inference, i.e, after `rbc_threshold`. Tweak the parameter above!\n",
    "\n",
    "vars_RL = agents.logger\n",
    "\n",
    "# list of dictionary of variables generated NORL - Optim w/o any RL. See actor.py#L166 for relevant variable names. eg. vars_RL[0]['E_grid']\n",
    "vars_NORL = agents.norl_logger\n",
    "\n",
    "# true E-grid values. NOTE: E_grid = E_grid_true. E_grid_pred = var[\"E_grid\"] for RL/Optim\n",
    "E_grid_true = np.array(E_grid_true)\n",
    "\n",
    "# E_grid net electricity consumption per building using RBC\n",
    "E_grid_RBC = np.array(E_grid_RBC)\n",
    "\n",
    "############## TODO: ENTER CODE HERE ##############\n",
    "\n",
    "\n",
    "# vars_RL = np.array(vars_RL)  # DImension - No.of days\n",
    "# RL_SOC_C = np.flatten(vars_RL[:]['SOC_C']).reshape(24*30,9)\n",
    "# RL_SOC_C.append(vars_RL[i]['SOC_C'])\n",
    "\n",
    "# #If indexing error, use the for loop\n",
    "# RL_SOC_C.append( vars_RL[i][key] )\n",
    "# RL_SOC_C = np.array(RL_SOC_C).flatten().reshape(days * 24, 9)\n",
    "\n",
    "\n",
    "# vars_A, vars_B, ..., vars_Z = [], [], ..., [] # RL\n",
    "# vars_A, vars_B, ..., vars_Z = [], [], ..., [] # NORL  #Already Defined\n",
    "\n",
    "keys = list(\"E_grid\", \"E_grid_sell\", \"E_hpC\", \"E_ehH\", \"SOC_bat\", \"SOC_H\", \"SOC_C\", \" action_bat\", \"action_H\", \"action_C\") \n",
    "\n",
    "for i in range(len(vars_RL)): #number of days of RL/NORL\n",
    "    RL_E_grid_pred.append(vars_RL[i][\"E_grid\"])\n",
    "    RL_E_grid_sell.append(vars_RL[i][\"E_grid_sell\"])\n",
    "    RL_E_hpC.append(vars_RL[i][\"E_hpC\"])\n",
    "    RL_E_ehH.append(vars_RL[i][\"E_ehH\"])\n",
    "    RL_SOC_bat.append(vars_RL[i][\"SOC_bat\"])\n",
    "    RL_SOC_H.append(vars_RL[i][\"SOC_H\"])\n",
    "    RL_SOC_C.append(vars_RL[i][\"SOC_C\"])\n",
    "    RL_action_bat.append(vars_RL[i][\"action_bat\"])\n",
    "    RL_action_C.append(vars_RL[i][\"action_C\"])\n",
    "    RL_action_H.append(vars_RL[i][\"action_H\"])\n",
    "    \n",
    "    NORL_E_grid_pred.append(vars_NORL[i][\"E_grid\"])\n",
    "    NORL_E_grid_sell.append(vars_NORL[i][\"E_grid_sell\"])\n",
    "    NORL_E_hpC.append(vars_NORL[i][\"E_hpC\"])\n",
    "    NORL_E_ehH.append(vars_NORL[i][\"E_ehH\"])\n",
    "    NORL_SOC_bat.append(vars_NORL[i][\"SOC_bat\"])\n",
    "    NORL_SOC_H.append(vars_NORL[i][\"SOC_H\"])\n",
    "    NORL_SOC_C.append(vars_NORL[i][\"SOC_C\"])\n",
    "    NORL_action_bat.append(vars_NORL[i][\"action_bat\"])\n",
    "    NORL_action_C.append(vars_NORL[i][\"action_C\"])\n",
    "    NORL_action_H.append(vars_NORL[i][\"action_H\"])\n",
    "\n",
    "# ### flatten out to get hour per building\n",
    "\n",
    "RL_E_grid = np.array(RL_E_grid).flatten().reshape(len(vars_RL) * 24, 9) # hours x num_buildings\n",
    "RL_E_grid_sell = np.array(RL_E_grid_sell).flatten().reshape(len(vars_RL) * 24, 9) # hours x num_buildings\n",
    "RL_E_hpC = np.array(RL_E_hpC).flatten().reshape(len(vars_RL) * 24, 9) # hours x num_buildings\n",
    "RL_E_ehH = np.array(RL_E_ehH).flatten().reshape(len(vars_RL) * 24, 9) # hours x num_buildings\n",
    "RL_SOC_bat = np.array(RL_SOC_bat).flatten().reshape(len(vars_RL) * 24, 9) # hours x num_buildings\n",
    "RL_SOC_H = np.array(RL_SOC_H).flatten().reshape(len(vars_RL) * 24, 9) # hours x num_buildings\n",
    "RL_SOC_C = np.array(RL_SOC_C).flatten().reshape(len(vars_RL) * 24, 9) # hours x num_buildings\n",
    "RL_action_bat = np.array(RL_action_bat).flatten().reshape(len(vars_RL) * 24, 9) # hours x num_buildings\n",
    "RL_action_C = np.array(RL_action_C).flatten().reshape(len(vars_RL) * 24, 9) # hours x num_buildings\n",
    "RL_action_H = np.array(RL_action_H).flatten().reshape(len(vars_RL) * 24, 9) # hours x num_buildings\n",
    "\n",
    "NORL_E_grid = np.array(NORL_E_grid).flatten().reshape(len(vars_NORL) * 24, 9) # hours x num_buildings\n",
    "NORL_E_grid_sell = np.array(RL_E_grid_sell).flatten().reshape(len(vars_NORL) * 24, 9) # hours x num_buildings\n",
    "NORL_E_hpC = np.array(NORL_E_hpC).flatten().reshape(len(vars_NORL) * 24, 9) # hours x num_buildings\n",
    "NORL_E_ehH = np.array(NORL_E_ehH).flatten().reshape(len(vars_NORL) * 24, 9) # hours x num_buildings\n",
    "NORL_SOC_bat = np.array(NORL_SOC_bat).flatten().reshape(len(vars_NORL) * 24, 9) # hours x num_buildings\n",
    "NORL_SOC_H = np.array(NORL_SOC_H).flatten().reshape(len(vars_NORL) * 24, 9) # hours x num_buildings\n",
    "NORL_SOC_C = np.array(NORL_SOC_C).flatten().reshape(len(vars_NORL) * 24, 9) # hours x num_buildings\n",
    "NORL_action_bat = np.array(NORL_action_bat).flatten().reshape(len(vars_NORL) * 24, 9) # hours x num_buildings\n",
    "NORL_action_C = np.array(NORL_action_C).flatten().reshape(len(vars_NORL) * 24, 9) # hours x num_buildings\n",
    "NORL_action_H = np.array(NORL_action_H).flatten().reshape(len(vars_NORL) * 24, 9) # hours x num_buildings\n",
    "\n",
    "\n",
    "\n",
    "# plot predicted E_grid\n",
    "# week = end_time - 24 * 3  # plots last week of the month data\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        bid = i * 3 + j\n",
    "        axs[i, j].set_title(f\"Building {bid + 1}\")\n",
    "        axs[i, j].plot(\n",
    "            RL_Egrid[:,i*3+j], label=\"RL_Egrid\"\n",
    "        )  \n",
    "        axs[i, j].plot(\n",
    "            NORL_Egrid_pred[:,i*3+j],\n",
    "            \"gx\",\n",
    "            label=\"NORL Egrid\",\n",
    "        )  # plots per month\n",
    "#         axs[i, j].plot(\n",
    "#             RBC_Egrid[bid][week:], label=\"True E grid: RBC\"\n",
    "#         )  # plot true E grid\n",
    "        axs[i, j].grid()\n",
    "        if j == 0:\n",
    "            axs[i, j].set_ylabel(\"E grid\")\n",
    "        if i == 0:\n",
    "            axs[i, j].set_xlabel(\"Hour\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents.E_grid_planned_day.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: insert code here\n",
    "\n",
    "### plot\n",
    "# plt.plot(vars_A_RL[:, 0])\n",
    "# plt.plot(vars_A_NORL[:, 0])\n",
    "# plt.plot(vars_A_RBC[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rewards = np.zeros(shape=(7, 24, 9)) # days, hours, buildings\n",
    "for i, day in enumerate(agents.memory.replay_memory):\n",
    "    _reward = np.array(day[\"reward\"])\n",
    "    rewards[i] = _reward\n",
    "rewards = rewards.reshape((7 * 24, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the variable axs for multiple Axes\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15, 15)) # 9 buildings\n",
    "\n",
    "id = 0\n",
    "for r in range(3):\n",
    "    for c in range(3):\n",
    "        axs[r, c].plot(rewards[:, id])\n",
    "        axs[r, c].set_title(f\"Building {id + 1}\")\n",
    "        id += 1\n",
    "        \n",
    "# set labels\n",
    "plt.setp(axs[-1, :], xlabel='Hour')\n",
    "plt.setp(axs[:, 0], ylabel='Reward')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
